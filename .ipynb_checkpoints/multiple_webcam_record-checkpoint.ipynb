{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d93545df",
   "metadata": {},
   "source": [
    "# Recording from Multiple Webcams Synchronously while LSL Streaming\n",
    "<br>\n",
    "<div align=\"center\">Šárka Kadavá (sarka.kadava@donders.ru.nl)</div>\n",
    "<div align=\"center\">Justin Snelders (justin.snelders@ru.nl)</div>\n",
    "<div align=\"center\">Wim Pouw (wim.pouw@donders.ru.nl)</div>\n",
    "\n",
    "<img src=\"Images/envision_banner.png\" alt=\"isolated\" width=\"300\"/>\n",
    "\n",
    "## Info documents\n",
    "\n",
    "* location Repository:  https://github.com/sarkadava/multiple_webcam_recording_for3Dtracking\n",
    "\n",
    "* location Jupyter notebook: https://github.com/sarkadava/multiple_webcam_recording_for3Dtracking/blob/main/webcam_scripts.ipynb\n",
    "\n",
    "# requirements\n",
    "Please install the packages in requirements.txt \n",
    "\n",
    "## Was this helpful\n",
    "citation for this module: Kadavá, S., Snelder, J., Pouw (2024). Recording from Multiple Webcams Synchronously while LSL Streaming [the day you viewed the site]. Retrieved from: https://envisionbox.org/multiple_webcam_record.html\n",
    "\n",
    "## Introduction\n",
    "In some of the modules on envisionBox we perform 3D tracking on multiple cameras that are recording synchronously. Before we started using those types of methods, we found that it is non-trivial to do actual recordings from multiple cameras in a synchronous way. Therefore we share a script here that allows to record from three webcams while also streaming information about the framenumbers to an LSL stream.\n",
    "\n",
    "Through trial and error, we found that ffmpegcv was the most stable solution for recording 3 webcams simultaneously in a synchronous way. A good way to test whether your webcams are synchronous is holding a stopwatch in front of all cameras, recording the videos, and compare for each frame if all videos show the same time. \n",
    "\n",
    "#### LSL stream, what is it good for?\n",
    "Often you want to combine audio and other signals with video. [LabStreamingLayer](https://labstreaminglayer.org/#/) is a very robust solution for this. LSL operates by collecting signal streams. In this script we create one such stream, whereby we stream the frame number f(t) at some time t. In LSL recording (using LSL labrecorder) you can write the stream to a file, and then LSL will store the framenumber alongside a common timestamp. You can then later align your frame number with the common time stamp, thereby ensuring a) that even when frames are dropped or collected with different intervals you can give the actual time of the frame recording, and b) you can align your other signals with very high precision to the frame (which may for example be the basis for your kinematic measurements). For example, we might also stream a accelerometer signal on a different PC on the network, and this stream will also be collected with a LSL recorder and given a common timestamp. Since the acceleration signal and the framenumbers are timestamped with a common clock (note different systems generally have different clocks) they can be synced and aligned.\n",
    "\n",
    "We are here assuming that you are already working with LSL. At some later moment we might do a LSL tutorial if needed. If you just want to use the script for recording that is fine too, you could either leave the script as is, or you can comment out parts that refer to LSL (and just write the videos to a disc).\n",
    "\n",
    "### Acknowledgements\n",
    "We want to thank [Pascal de Water](https://www.ru.nl/socialsciences/technicalsupportgroup/about/staff/water-de-(pascal)/) at the Donders Institute for Brain, Cognition and Behaviour for first helping us to a demo script that does streaming and webcam recording. The current script is a heavily adapted  version (making use of ffmpegcv instaed of opencv2) of that original script.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe838bdc",
   "metadata": {},
   "source": [
    "# Step 1: Recording"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f423ee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2      # for video processing functions\n",
    "import datetime # for time registration\n",
    "import time     # for time registration\n",
    "from pylsl import StreamInfo, StreamOutlet, local_clock # for LSL streaming\n",
    "import threading # for creating threads to do multiple things at once\n",
    "import ctypes # data formatting\n",
    "import sys # general functions\n",
    "import os # general functions\n",
    "import ffmpegcv # important package for saving the videos quickly\n",
    "import tqdm #progressbar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f0b88d",
   "metadata": {},
   "source": [
    "### Things to note\n",
    "\n",
    "- Sometimes your webcam indices are different for your system. We now assume that 1, 2, and 3 are the IDS of your three webcams you need. You can change this if the right webcams are not displaying.\n",
    "- Do check whether your CPU is overloaded, this may lead to asynchronies. Your CPU should not exceed 80% load.\n",
    "- If you want to have good tracking, ideally you have cameras with fast shutter speed (e.g., 1/200) and framerate (60Hz), we are using Elgato Facecams in the lab.\n",
    "- The video also checks the framerate and prints it on the videos for sanity check. This demo now assumes framerate of 30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6c52d46d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# presets\n",
    "cams = [0, 1, 2] # change numbers if cameras not displayed\n",
    "set_framerate = 30\n",
    "# Define the resolution\n",
    "width = 960\n",
    "height = 540"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1815d747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.9.13 (main, Aug 25 2022, 23:51:50) [MSC v.1916 64 bit (AMD64)]\n",
      "Starting LSL webcam: Press Q to stop!\n",
      "Camera 1 opened\n",
      "Camera 2 opened\n",
      "Camera 3 opened\n",
      "Enter ID: test\n",
      "Data saved in: C:\\Research_Projects\\multiple_webcam_recording_for3Dtracking\\data\\test_2024-02-13_output.avi\n",
      "Stop\n"
     ]
    }
   ],
   "source": [
    "# Recording main \n",
    "print(sys.version)\n",
    "\n",
    "# labstreaminglayer sets\n",
    "#set sleep to 1ms accuracy \n",
    "winmm = ctypes.WinDLL('winmm')\n",
    "winmm.timeBeginPeriod(1)\n",
    "\n",
    "# setup streaming capture device\n",
    "def sendLSLFrames(camera_thread):\n",
    "    stamp = local_clock()\n",
    "    while camera_thread.is_alive():\n",
    "        time.sleep(0.001)\n",
    "        while local_clock() < stamp:\n",
    "            pass\n",
    "        stamp = local_clock() + (1.0/freq)\n",
    "        outlet.push_sample([frame_counter1])#, local_clock())\n",
    "\n",
    "# open the three cameras and return as variables\n",
    "def open_cameras():\n",
    "    # Open the cameras and set the resolution\n",
    "    cap1 = cv2.VideoCapture(cams[0], cv2.CAP_DSHOW)\n",
    "    cap1.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap1.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    print(\"Camera 1 opened\")\n",
    "\n",
    "    cap2 = cv2.VideoCapture(cams[1], cv2.CAP_DSHOW)\n",
    "    cap2.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap2.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    print(\"Camera 2 opened\")\n",
    "\n",
    "    cap3 = cv2.VideoCapture(cams[2], cv2.CAP_DSHOW)\n",
    "    cap3.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "    cap3.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "    print(\"Camera 3 opened\")\n",
    "    return cap1, cap2, cap3\n",
    "\n",
    "# MAIN CAMERA FUNCTION\n",
    "def getWebcamData(cap1, cap2, cap3, video_writer):\n",
    "    global frame_counter1\n",
    "    global frame_counter2\n",
    "    global frame_counter3\n",
    "\n",
    "    prev = 0\n",
    "    framecounter_fr = 0\n",
    "    running_framerate = 0\n",
    "\n",
    "    # main camera loop\n",
    "    while True:\n",
    "        # read frames from each webcam stream\n",
    "        frames = read_frames(cap1, cap2, cap3)\n",
    "        if len(frames) == 1: # If read_frames returned error code, break main loop\n",
    "            break\n",
    "        frame1, frame2, frame3 = frames\n",
    "        \n",
    "        # added to make sure that cams are synchronized\n",
    "        time_elapsed = time.time() - prev\n",
    "        if time_elapsed > 1. / frame_rate:\n",
    "            prev = time.time()\n",
    "            # frame counter\n",
    "            frame_counter1 += 1\n",
    "            frame_counter2 += 1\n",
    "            frame_counter3 += 1\n",
    "            \n",
    "            # estimate the frame rate after some initial ramp up phase\n",
    "            if frame_counter1 == 1000:\n",
    "                framecounter_fr += 1\n",
    "                timegetfor_fr = time.time()\n",
    "            elif frame_counter1 >= 1001:\n",
    "                framecounter_fr += 1\n",
    "                timepassed_fr = timegetfor_fr - time.time()\n",
    "                running_framerate = abs(round(framecounter_fr / timepassed_fr, 2))\n",
    "\n",
    "            # combine frames for display and VideoWriter\n",
    "            combined_frames, combined_frames_dis = combine_frames(frame1, frame2, frame3, running_framerate)\n",
    "\n",
    "            # write combined frames to the VideoWriter\n",
    "            video_writer.write(combined_frames)\n",
    "   \n",
    "            # display the combined frames\n",
    "            cv2.imshow('Webcam Streams', combined_frames_dis)\n",
    "\n",
    "            # check for the 'q' key to exit\n",
    "            if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                break\n",
    "\n",
    "    video_writer.release()\n",
    "\n",
    "    # release the webcam resources\n",
    "    cap1.release()\n",
    "    cap2.release()\n",
    "    cap3.release()\n",
    "\n",
    "    # close the display window\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# read frames from 3 cameras, returns list of either frames or error code\n",
    "def read_frames(cap1, cap2, cap3):\n",
    "    ret1, frame1 = cap1.read() # read frame camera one\n",
    "    if not ret1:\n",
    "        print(\"Can't receive frame from camera one. Exiting...\")\n",
    "        return [-1]\n",
    "    ret2, frame2 = cap2.read() # read frame camera two\n",
    "    if not ret2:\n",
    "        print(\"Can't receive frame from camera two. Exiting...\")\n",
    "        return [-1]\n",
    "    ret3, frame3 = cap3.read() # read frame camera three\n",
    "    if not ret3:\n",
    "        print(\"Can't receive frame from camera three. Exiting...\")\n",
    "        return [-1]\n",
    "    return [frame1, frame2, frame3]\n",
    "\n",
    "\n",
    "# combines frames to instances for display and video writer, returns instances\n",
    "def combine_frames(frame1, frame2, frame3, framerate):\n",
    "    # rotate the frames\n",
    "    frame1 = cv2.rotate(frame1, cv2.ROTATE_90_CLOCKWISE) # rotate image\n",
    "    frame2 = cv2.rotate(frame2, cv2.ROTATE_90_CLOCKWISE) # rotate image\n",
    "    frame3 = cv2.rotate(frame3, cv2.ROTATE_90_CLOCKWISE) # rotate image\n",
    "\n",
    "    # add info to show on screen\n",
    "    cv2.putText(frame1, str(frame_counter1), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "    cv2.putText(frame2, str(frame_counter2), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "    cv2.putText(frame3, str(frame_counter3), (20, 40), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "    \n",
    "    # show FPS after initial ramp up phase\n",
    "    if frame_counter1 >= 1001:\n",
    "        cv2.putText(frame1, 'fps: '+ str(framerate), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "        cv2.putText(frame2, 'fps: '+str(framerate), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "        cv2.putText(frame3, 'fps: '+str(framerate), (20, 60), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 0, 0))\n",
    "    \n",
    "    # resize the frames for display\n",
    "    frame1_dis = cv2.resize(frame1, (240, 426), interpolation=cv2.INTER_LINEAR) # this resize results in the highest fps\n",
    "    frame2_dis = cv2.resize(frame2, (240, 426), interpolation=cv2.INTER_LINEAR)\n",
    "    frame3_dis = cv2.resize(frame3, (240, 426), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "    # combine frames horizontally\n",
    "    combined_frames = cv2.hconcat([frame1, frame2, frame3])\n",
    "    combined_frames_dis = cv2.hconcat([frame1_dis, frame2_dis, frame3_dis])\n",
    "\n",
    "    return combined_frames, combined_frames_dis\n",
    "\n",
    "################ LABSTREAMLAYER INPUTS ################\n",
    "freq = 500\n",
    "frame_rate = 200.0 # when it's set on 60, the max fps we get is around 40, if on 200, we get to 60\n",
    "data_size = 20\n",
    "stream_info = StreamInfo(name='MyWebcamFrameStream', type='frameNR', channel_count=1, channel_format='int32', nominal_srate = freq, source_id='MyWebcamFrameStream')\n",
    "outlet = StreamOutlet(stream_info)  # broadcast the stream\n",
    "\n",
    "################ Execute LSL threading ################\n",
    "\n",
    "# initialize global frame counters\n",
    "frame_counter1, frame_counter2, frame_counter3 = 1, 1, 1\n",
    "\n",
    "# open the default webcam devices\n",
    "print(\"Starting LSL webcam: Press Q to stop!\")\n",
    "cap1, cap2, cap3 = open_cameras()\n",
    "\n",
    "\n",
    "# specify file location of output\n",
    "pcn_id = input('Enter ID: ')\n",
    "time_stamp = datetime.datetime.now().strftime('%Y-%m-%d')\n",
    "file_name = pcn_id + '_' + time_stamp + '_output.avi'\n",
    "vidloc = os.getcwd() + '\\\\data\\\\' + file_name # Specify output location\n",
    "print('Data saved in: ' + vidloc)\n",
    "\n",
    "# set up the VideoWriter\n",
    "video_writer = ffmpegcv.VideoWriter(vidloc, 'rawvideo', set_framerate) # 'h264' possible, but lower quality\n",
    "\n",
    "# initialize the LSL threads\n",
    "camera_thread = threading.Thread(target=getWebcamData, args=(cap1, cap2, cap3, video_writer))\n",
    "camera_thread.start()\n",
    "sendLSLFrames(camera_thread)\n",
    "\n",
    "# notify when program has concluded\n",
    "print(\"Stop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8a7504",
   "metadata": {},
   "source": [
    "# Checking timing\n",
    "We would recommend checking the timing of the frames. Here we recorded a stopwatch in view by the three webcams that are recording. You will see that the webcams are showing same times, or 1ms difference at most if you inspect closely some frames. Just play and stop the video at random frames while the stopwatch is in view."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ed24ffab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./data/test_compr.mp4\" controls  width=\"540\"  height=\"540\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(\"./data/test_compr.mp4\", width=540, height=540)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4142134f",
   "metadata": {},
   "source": [
    "# Optional Step 2: Compressing into smaller videos\n",
    "Currently we are recording in a very raw format, which means that there is almost no compression used for the codec. However, you might want to resize the videos. Since the original recording was too big for github, we used the below code to recompress the video into a managable size. This video is uploaded in github. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7da7e02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compressing Video: 100%|████████████████████████████████████████████████| 575/575 [00:07<00:00, 77.27frames/s]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import datetime\n",
    "from pylsl import StreamInfo, StreamOutlet, local_clock\n",
    "import threading\n",
    "import time\n",
    "import ctypes\n",
    "import sys\n",
    "import os\n",
    "import ffmpegcv\n",
    "# import signal\n",
    "import tqdm\n",
    "\n",
    "\n",
    "# recompress\n",
    "filename = 'test'\n",
    "\n",
    "vidloc = os.getcwd() + '\\\\data\\\\' + filename + '.avi' # Specify output location\n",
    "# Read the written video\n",
    "cap = cv2.VideoCapture(vidloc)\n",
    "\n",
    "# Get video information\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "frame_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "frame_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "# Specify the codec and create VideoWriter object for compressed video\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')  # You can change the codec as needed\n",
    "compressed_file_name = vidloc.replace('.avi', '_compr.avi')\n",
    "compressed_video_writer = cv2.VideoWriter(compressed_file_name, fourcc, fps, (frame_width, frame_height))\n",
    "\n",
    "# Display progress bar using tqdm\n",
    "for _ in tqdm.tqdm(range(total_frames), desc=\"Compressing Video\", unit=\"frames\"):\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "    # Compress the frame (you can apply additional compression settings if needed)\n",
    "    compressed_frame = cv2.resize(frame, (frame_width, frame_height), interpolation=cv2.INTER_AREA)\n",
    "    # Write the compressed frame to the VideoWriter\n",
    "    compressed_video_writer.write(compressed_frame)\n",
    "\n",
    "# Release the VideoCapture and VideoWriter resources\n",
    "cap.release()\n",
    "compressed_video_writer.release()\n",
    "\n",
    "# Close the display window\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9898aa4",
   "metadata": {},
   "source": [
    "# Optional Step 3: Cutting the videos for individual processing\n",
    "Perhaps you want to work with the videos seperately. The following codes cuts them in three again. It will save this data in a test folder, in raw-2d, which would also be an input for further tracking with openpose or pose2sim for example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4a5b44e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.\\\\data\\\\test_compr.avi']\n",
      "working on file: .\\data\\test_compr.avi\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from moviepy.editor import VideoFileClip, concatenate_videoclips\n",
    "import cv2\n",
    "import ffmpeg\n",
    "\n",
    "# videodata \n",
    "videodata = '.\\\\data\\\\'\n",
    "outputfolder = '.\\\\data\\\\'\n",
    "# outputfolder = curfolder + '\\\\test_output\\\\'\n",
    "\n",
    "# load in the calibration videos (avi)\n",
    "videos = [videodata+'test_compr.avi']\n",
    "\n",
    "print(videos)\n",
    "\n",
    "\n",
    "def split_camera_views(input_file, output_files):\n",
    "    cap = cv2.VideoCapture(input_file)\n",
    "\n",
    "    # Get the width and height of each camera view\n",
    "    num_cameras = 3\n",
    "    width_per_camera = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)) // num_cameras\n",
    "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    frame_rate = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "    # Create VideoWriters for each camera\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "    out_cam1 = cv2.VideoWriter(output_files[0], fourcc, frame_rate, (width_per_camera, height))\n",
    "    out_cam2 = cv2.VideoWriter(output_files[1], fourcc, frame_rate, (width_per_camera, height))\n",
    "    out_cam3 = cv2.VideoWriter(output_files[2], fourcc, frame_rate, (width_per_camera, height))\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        # Check if the frame is None (end of video)\n",
    "        if frame is None:\n",
    "            break\n",
    "\n",
    "        # Break the frame into three parts\n",
    "        camera1_frame = frame[:, :width_per_camera, :]\n",
    "        camera2_frame = frame[:, width_per_camera:2*width_per_camera, :]\n",
    "        camera3_frame = frame[:, 2*width_per_camera:, :]\n",
    "\n",
    "        # Display each camera view separately (optional)\n",
    "        cv2.imshow('Camera 1', camera1_frame)\n",
    "        cv2.imshow('Camera 2', camera2_frame)\n",
    "        cv2.imshow('Camera 3', camera3_frame)\n",
    "\n",
    "        # Write frames to video files\n",
    "        out_cam1.write(camera1_frame)\n",
    "        out_cam2.write(camera2_frame)\n",
    "        out_cam3.write(camera3_frame)\n",
    "\n",
    "        if cv2.waitKey(1) == 27:\n",
    "            break\n",
    "\n",
    "    # Release VideoWriters and VideoCapture\n",
    "    out_cam1.release()\n",
    "    out_cam2.release()\n",
    "    out_cam3.release()\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "# loop over files in folder and split them\n",
    "for file in videos:\n",
    "    print(\"working on file: \"+file)\n",
    "    # Get the name of the file without the extension\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    \n",
    "    trialID = filename.split(\"_\")[0]\n",
    "    \n",
    "    # create an empty folder with name of the sessionIndex\n",
    "    os.makedirs(os.path.join(outputfolder, trialID))\n",
    "    # inside this folder, create empty folder 'raw-2d'\n",
    "    os.makedirs(os.path.join(outputfolder, trialID, 'raw-2d'))\n",
    "\n",
    "    # create output file names, and save the three videos into the new created folder raw-2d within the sessionIndex folder\n",
    "    output_files = [\n",
    "        os.path.join(outputfolder, trialID, 'raw-2d', filename + '_cam1.avi'),\n",
    "        os.path.join(outputfolder, trialID, 'raw-2d', filename + '_cam2.avi'),\n",
    "        os.path.join(outputfolder, trialID, 'raw-2d', filename + '_cam3.avi')\n",
    "    ]\n",
    "\n",
    "    # Split the camera views\n",
    "    split_camera_views(file, output_files)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
